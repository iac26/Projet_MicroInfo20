\documentclass{rapport}
\usepackage[utf8]{inputenc}

\titre{Projet MICRO-315}
\soustitre{Sound Locator}
\auteur{Timon Binder}{Iacopo Sprenger}
\date{May 2020}


\begin{document}

\maketitre
\tableofcontents
\newpage
\section{Introduction}

Pour notre projet de Microinformatique, nous avons décidé de réaliser un robot qui peut naviguer un champ d'obstacles en direction d'une cible sonore et visuelle. La cible sera un haut-parleur entouré d'une feuille de papier sur laquelle sont imprimées des lignes noires horizontales. Le haut-parleur va émettre un sifflement aigu. 


\section{Principe de fonctionnement}

Notre programme est décomposé en modules. Chaque module va s'occuper d'acquérir, d'analyser et de rendre disponibles les données d'un capteur. Finalement le module de navigation va s'occuper de diriger les moteurs selon les données environnementales.

\subsection{Modules d'analyse des capteurs}

\subsubsection{Analyse du son}

\fig{son_dir.png}{son_dir}{
Graphe montrant l'évolution des différences de phases entre deux paires de micros ainsi que l'angle d'incidence du son calculé lorsque nous avons placé un haut-parleur émettant une sinusoïdale a 900hz d'abord a gauche du robot (0-100 samples) puis devant (110-210 samples) puis a droite (240-320 samples) et finalement derrière (330-410 samples). On peut voir que lorsque la source est derrière l'angle oscille entre -pi et pi.
}{0.7\linewidth}{Phases et angles calculés a partir des micros de l'e-puck}


L'analyse du son est géré dans un callback appelée par le driver du microphone a chque fois que des échantillons sont prêts.
Nous utilisons la forme complexe de la FFT afin d'obtenir la phase des divers signaux a la fréquence maximale. Nous trouvons finalement l'angle d'incidence du son en faisant l'arc tangente du déphasage avant-arrière divisé par le déphasage droite-gauche. On peut voir dans la Figure \ref{son_dir} que les valeurs obtenues avec cette méthode sont approximativement correctes.\\
Pour améliorer nos résultats nous orientons le robot avec la valeur d'angle médiane sur 50 mesures. Cette méthode nous donne de bien meilleurs résultats. Cependant elle ne permet pas un ajustement temps réel de l'orientation du robot car celui-ci doit attendre que les 50 mesures soient terminées.



\subsubsection{Analyse d'images}

\figDeux{Capture.PNG}{image_detect.PNG}{image_detec}{
Images prises avec la caméra de l'e-puck. On indique en violet le centre et en rose les extrémités du pattern calculés sur le robot. En vert, rouge et bleu on indique les flans et les colonnes du pattern calculés sur l'ordinateur avec le même algorithme que sur le robot pour aider au debug.
}{0.7\linewidth}{Photos transmises depuis l'e-puck}

L'analyse d'images est géré par deux threads, un pour capturer la photo et un pour l'analyser.
On capture une photo en nuances de gris a deux dimensions et on cherche un pattern rayé noir-blanc horizontal avec les lignes blanches deux fois plus larges que les lignes noires. Pour faire cela nous avons d'abord une fonction qui analyse une colonne de l'image et détermine si celle-ci appartient au pattern. Nous analysons les colonnes de l'image par dichotomie en partant du centre pour essayer de trouver l'emplacement grossier du pattern sur l'image. lorsque une colonne est trouvée on explore vers la droite et vers la gauche afin de trouver le début et la fin du pattern. Finalement, nous pouvons calculer le centre et la largeur du pattern pour la navigation.\\

Nous ne savions initialement pas trop comment faire pour détecter un pattern, nous avons donc commencé par envoyer les images a l'ordinateur et développer l'algorithme de détection sur python avec la possibilité d'afficher des données de debug directement sur la photo. Une fois satisfaits de notre algorithme, nous l'avons adapté et porté sur le robot. On a vérifié son fonctionnement en comparant les résultats de python et de l'e-puck comme on peut voir dans la Figure \ref{image_detec}.



\subsubsection{Détecteur de distance}

\fig{distances.png}{distanc}{Graphe montrant la distance réelle d'une feuille blanche au capteurs IR en fonction de la valeur retournée par le capteur. Nous avons ensuite extrapolé une fonction (trendline puissance) qui relie les mesures au monde réel afin d'obtenir des valeurs de distance linéaires.}{0.65\linewidth}{Ajustement de la distance réelle par rapport à la distance mesurée}

Les capteurs de distances sont gérés dans un thread. On aurait pu se passer d'un thread pour ce module, mais puisque on rejette certaines mesures, on souhaite avoir accès a la dernière mesure valide. Ceci est seulement possible avec un thread qui lis périodiquement les capteurs.\\
Puisque nous utilisons les distances mesurées par les capteurs de proximité pour ajuster la position du robot avec des contrôleurs proportionnels, il est nécessaire que les valeurs mesurées suivent une fonction affine. Nous avons obtenu la relation présente dans la Figure \ref{distanc}. En plaçant une feuille blanche devant le robot a diverses distances connues tout en observant la sortie des capteurs. Afin d'éviter au processeur de devoir calculer une puissance étrange, nous avons approximé la distance aux capteurs par cette relation: $$distance\ [mm]=\frac{438.85}{\sqrt{valeur\ du\ capteur}}$$ 
\\
Le module de gestion des capteurs de proximité sert aussi a rejeter les mesures étranges qui apparaissent des fois.

%\subsubsection{Détecteur de pickup}
%Lors du développement de notre programme, nous avons eu parfois des bugs qui font rouler le robot n'importe'où. Afin de pouvoir tranquillement le ramasser et le brancher a l'ordinateur pour corriger le bug sans que les moteurs tournent a pleine vitesse, nous avons implémenté un module qui détecte si quelqu'un prend le robot dans sa main. Pour faire cela on calcule une moyenne de mesures de l'IMU et si la valeur maximale des mesures est suffisamment loin de la moyenne, c'est que le robot a été ramassé. Cela force la machine d'états finis principale dans l'état PAUSED.
\subsection{Module de navigation}
Le module de navigation est géré a l'aide d'une machine d'états finis (FSM). Les diverses étapes de la navigation du robot jusqu'à son objectif sont des états et certaines étapes complexes tels que le contournement d'un obstacle sont eux-mêmes gérés par une FSM.


\subsubsection{Machine d'états finis principale}

Le robot commence en mode \texttt{SOUND SEARCH}, dans lequel il tente de s'orienter face au son. Une fois orienté il entre en mode \texttt{MOVE FORWARD}, dans lequel il avance jusqu'à ce que la direction du son soit fausse, un obstacle se trouve devant lui ou que le pattern d'arrivée soit visible.\\
Si le robot est dans l'état \texttt{FINAL APPROACH} il considère automatiquement le prochain obstacle rencontré comme l'arrivée. Cet état est nécessaire car le pattern n'est parfois pas détecté depuis trop proche et le robot le confond avec un obstacle a contourner. Ceci est dû au fait que pas assez de lignes sont visibles verticalement dans l'image.\\
Le dernier état est \texttt{ARRIVED}, qui comme son nom l'indique signifie que le robot est arrivé a destination et n'as plus rien a faire.
\begin{figure}[ht]
\centering
 \textbf{Machine d'états finis principale}\par\medskip
\begin{tikzpicture}
\node[state, initial, fill=gray!20] (ss) {\begin{tabular}{c} SOUND \\ SEARCH \end{tabular}};

\node[state, above right of=ss, fill=gray!20] (fw) {\begin{tabular}{c} FOLLOW \\ WALL \end{tabular}};
\node[state, right of=ss, node distance=6cm] (mv) {\begin{tabular}{c} MOVE \\ FORWARD \end{tabular}};

\node[state, below right of=ss, fill=gray!20] (ti) {\begin{tabular}{c} TARGET \\ IN SIGHT \end{tabular}};
\node[state, right of=ti] (fa) {\begin{tabular}{c} FINAL \\ APPROACH \end{tabular}};
\node[state, above right of=fa] (aa) {\begin{tabular}{c} ARRIVED \end{tabular}};

%\node[state, right of=fw, node distance=9cm] (pp) {\begin{tabular}{c} PAUSED \end{tabular}};

\draw   
(ss) edge[bend left=5, sloped, anchor=south] node{pattern visible} (ti)
(ss) edge[bend left=5, above, sloped, anchor=south] node{dir. du son en face} (mv)
(mv) edge[bend left=5, above, sloped, anchor=north] node{dir. du son pas en face} (ss)
(mv) edge[right, sloped, anchor=south] node{obstacle trouvé} (fw)
(mv) edge[right, sloped, anchor=south] node{pattern visible} (ti)
(ti) edge[above, sloped, anchor=south] node{pattern assez proche} (fa)
(fa) edge[above, sloped, anchor=south] node{obstacle trouvé} (aa)
(fw) edge[above, sloped, anchor=south] node{obstacle disparu} (ss)
(fw) edge[bend left=15, above, sloped, anchor=south] node{obstacle est le pattern} (aa)
(ti) edge[bend left=5, above, sloped, anchor=north] node{pattern perdu} (ss)
(ti) edge[bend right=60, looseness=2, above, sloped, anchor=south] node{obstacle trouvé} (fw);

\end{tikzpicture}
\caption{Graphe montrant les relations entres les différents états de la FSM principale. Les états plus foncés sont eux mêmes des machines d'états finis. \texttt{SOUND SEARCH} est l'état initial.}
\label{machine etat}
\end{figure}

\subsubsection{Recherche du son}
Pour la recherche du son, dont le graphe se trouve dans la Figure \ref{FSM_ss}, on commence par attendre le résultat du module d'analyse audio. Une fois le résultat disponible, on passe dans l'état \texttt{ROTATE} qui va tourner le robot face au son.
Une fois le robot tourné, on retourne dans l'état \texttt{LOCATE} et on attend a nouveau. Ce retour en arrière permet de confirmer que la rotation ait fonctionné comme prévu et permet aussi de confirmer que la direction du son était correcte par une seconde mesure. \\
Tout au long du processus de localisation du son, il est possible que le pattern d'arrivée apparaisse, dans ce cas on a plus besoin du son et la machine d'états finis principale entre en mode \texttt{TARGET IN SIGHT}.


\begin{figure}[!ht]
\centering
\textbf{Machine d'états finis de recherche du son}\par\medskip
\begin{tikzpicture}
\node[state, initial] (sl) {\begin{tabular}{c} LOCATE \end{tabular}};
\node[state, above right of=sl, fill=gray!20, dashed] (ti) {\begin{tabular}{c} TARGET \\ IN SIGHT \end{tabular}};
\node[state, below right of=ti] (sr) {\begin{tabular}{c} ROTATE \end{tabular}};
\node[state, above left of=sl, dashed] (mv) {\begin{tabular}{c} MOVE \\ FORWARD \end{tabular}};

\draw   
(sl) edge[bend left=10, sloped, anchor=south] node{son detecté} (sr)
(sr) edge[bend left=10, sloped, anchor=north] node{rotation terminée} (sl)
(sl) edge[sloped, anchor=north] node{direction correcte} (mv)
(sl) edge[sloped, anchor=south] node{pattern visible} (ti)
(sr) edge[sloped, anchor=south] node{pattern visible} (ti)

;

\end{tikzpicture}
\caption{Graphe montrant les relations entres les différents états de la FSM de recherche du son. Les états plus foncés sont eux mêmes des FSM et les états en traits-tillés sont les sorties de cette FSM. \texttt{LOCATE} est l'état initial.}
\label{FSM_ss}
\end{figure}



\begin{figure}[!ht]
\centering
\textbf{Machine d'états finis de contournement d'obstacle}\par\medskip
\begin{tikzpicture}
\node[state] (ad) {\begin{tabular}{c} ADJUST \end{tabular}};
\node[state, above right of=ad, fill=gray!20, dashed] (ss) {\begin{tabular}{c} SOUND \\ SEARCH \end{tabular}};
\node[state, initial, above left of=ss] (al) {\begin{tabular}{c} ALIGN \end{tabular}};

\node[state, right of=ad] (rp) {\begin{tabular}{c} ROTATE P \end{tabular}};


\node[state, right of=ss] (ta) {\begin{tabular}{c} TURN \\ AROUND \end{tabular}};
\node[state,  right of=ta] (ff) {\begin{tabular}{c} FOLLOW \end{tabular}};
\node[state, right of=al] (rs) {\begin{tabular}{c} ROTATE S \end{tabular}};

\node[state, left of=ss, node distance=5.5cm, dashed] (aa) {\begin{tabular}{c} ARRIVED \end{tabular}};



\draw   
(ad) edge[bend left=5, sloped, anchor=south] node{alignement pas bon} (al)
(al) edge[bend left=5, sloped, anchor=south] node{alignement bon} (ad)
(ad) edge[sloped, anchor=south] node{bonne distance} (rp)
(rp) edge[bend right=20, sloped, anchor=north] node{rotation terminée} (ff)
(ff) edge[bend right=20, sloped, anchor=south] node{mur trop loin/proche} (rs)
(rs) edge[sloped, anchor=south] node{rotation terminée} (al)
(ff) edge[bend left=5, sloped, anchor=north] node{obstacle devant} (ta)
(ta) edge[bend left=5, sloped, anchor=south] node{rotation terminée} (ff)
(al) edge[sloped, anchor=south] node{mur disparu} (ss)
(ad) edge[sloped, anchor=south] node{mur disparu} (ss)
(rp) edge[sloped, anchor=south] node{mur disparu} (ss)
(ta) edge[sloped, anchor=south] node{mur disparu} (ss)
(ff) edge[bend right=30, sloped, anchor=south] node{mur disparu} (ss)
(al) edge[sloped, anchor=south] node{pattern visible} (aa)
(ad) edge[sloped, anchor=north] node{pattern visible} (aa);

\end{tikzpicture}
\caption{Graphe montrant les relations entres les différents états de la FSM de contournement d'obstacles. Les états plus foncés sont eux mêmes des FSM et les états en traits-tillés sont les sorties de cette FSM. \texttt{ALIGN} est l'état initial.}
\label{FSM_fw}
\end{figure}

\subsubsection{Contournement d'obstacle}
L'idée initiale du contournement d'obstacles était d'orienter le robot parallèle a l'obstacle, puis d'avancer en le maintenant a distance constante jusqu'à la fin du mur. Cependant, notre robot a le capteur IR2 défectueux ce qui nous force a utiliser une autre approche.\\
La nouvelle approche, dont le graphe se trouve dans la Figure \ref{FSM_fw} est de s'orienter perpendiculaire au mur a une certaine distance en utilisant les deux capteurs avant. L'état \texttt{ALIGN} va aligner la perpendicularité et l'état \texttt{ADJUST} va ajuster la distance. Une fois perpendiculaire on tourne le robot de exactement 90 degrés avec l'état \texttt{ROTATE P} et on avance en observant la distance au mur avec le capteur de coté. Il s'agit de l'état \texttt{FOLLOW}. Si le mur est trop loin ou trop proche, on tourne le robot pour qu'il soit perpendiculaire au mur et on recommence l'alignement.\\
Lorsque le robot suit un mur, et un obstacle se trouve devant lui on entre dans l'état \texttt{TURN AROUND} qui va pivoter le robot et repartir dans l'autre direction. Cette manoeuvre permet a notre robot de gérer un obstacle en "L".

\subsubsection{Pattern d'arrivée visible}
Dans la Figure \ref{FSM_ti} on peut voir le graphe de la machine d'états finis qui a le contrôle lorsque le pattern est détecté. On commence par aligner le robot avec le pattern dans \texttt{ALIGN}. Ensuite on avance tout en observant si un obstacle est détecté par les capteurs de proximité dans \texttt{APPROACH}. Une fois que le pattern apparaît suffisamment grand dans l'image, on suppose que le prochain obstacle détecté sera l'arrivée et on sors vers l'état \texttt{FINAL APPROACH}. 


\begin{figure}[!ht]
\centering
\textbf{Machine d'états finis de pattern visible}\par\medskip
\begin{tikzpicture}
\node[state, initial] (al) {\begin{tabular}{c} ALIGN \end{tabular}};
\node[state, right of=al] (ap) {\begin{tabular}{c} APPROACH \end{tabular}};
\node[state, above of=ap, dashed, fill=gray!20] (fw) {\begin{tabular}{c} FOLLOW \\ WALL \end{tabular}};
\node[state, right of=ap, dashed] (fa) {\begin{tabular}{c} FINAL \\ APPROACH \end{tabular}};
\node[state, above of=al, dashed, fill=gray!20] (ss) {\begin{tabular}{c} SOUND \\ SEARCH \end{tabular}};

\draw   
(al) edge[bend left=10, sloped, anchor=south] node{pattern centré} (ap)
(ap) edge[bend left=10, sloped, anchor=north] node{pattern décentré} (al)
(ap) edge[sloped, anchor=south] node{obstacle trouvé} (fw)
(ap) edge[sloped, anchor=south] node{pattern assez proche} (fa)
(al) edge[sloped, anchor=south] node{pattern disparu} (ss)
;

\end{tikzpicture}
\caption{Graphe montrant les relations entres les différents états de la FSM d'alignement du pattern visible. Les états plus foncés sont eux mêmes des FSM et les états en traits-tillés sont les sorties de cette FSM. \texttt{ALIGN} est l'état initial.}
\label{FSM_ti}
\end{figure}


\section{Résultats}
\subsection{Analyse du son}
Notre méthode d'utiliser les quatre microphones et la valeur médiane sur beaucoup d'échantillons, nous a permis de grandement améliorer nos résultats. Cependant, il reste encore des mesures incorrectes de temps a autre. Nous estimons que ces imprécisions viennent en grande partie de l'acoustique de la pièce dans laquelle nous travaillons car en allant dans un jardin, notre robot détecte l'angle juste a chaque fois. Finalement, nous avons attaché des tissus sur les murs de la pièce pour réduire les échos.

\subsection{Analyse d'images}
L'analyse d'images fonctionne très bien si la feuille rayée est bien illuminée. Sans illumination, on doit réduire le seuil de détection de flans ce qui engendre des faux positifs dans le décor. Nous avons donc opté pour la solution de pointer une lampe a la cible. \\
La détection du pattern fonctionne aussi étonnamment bien a plus grande distances (>1.5m) car on a un effet de battement sur le pattern rayé et il apparaît a la caméra comme des lignes plus épaisses.

\subsection{Contournement d'obstacles}
Notre algorithme de contournement d'obstacles fonctionne très bien sur des obstacles planaires, convexes et en forme de "L". Mais il reste coincé lorsqu'il est confronté a un obstacle concave tel qu'un "C" ou un "G". Pour sortir d'un tel coincement, le robot devrait mémoriser l'historique de ses déplacements et reconnaître qu'il est coincé. Notre programme ne prend en compte que son état actuel et pas le passé, il n'est donc pas capable de se sortir d'une telle situation.

\section{Conclusion}


%Depuis le début du projet on était capable de visualiser de comment on devrais être capable de résoudre ce problème.


%mais ça était clairement pas la première version qui a bien marche....

%avec chaque problème résolu il y a un autre qui apparu.... 

%et avec chaque problème qui était résolu on a appris quelque chose.

%Pendant nôtre projet on a rencontre que: le sons que ce refléter partout, .... un capteur de distance ne marche même pas etc.  .........
%filtrage....... adapter l'enivrement pour mieux absorber les ondes réfléchis par des mur ou des obstacles. 




Ce projet nous a permis de réaliser qu'il n'est pas toujours évident de passer d'un concept théorique a une implémentation physique qui marche bien. Nos principaux objectifs étaient de détecter la direction du son, contourner un obstacle et finalement détecter un pattern visuel. 
Ces trois fonctions sont relativement simples a implémenter en théorie mais en pratique nous avons rencontré une multitude de complications: Les échos et le bruit externe pour l'analyse sonore et la luminosité et l'arrière plan pour l'analyse d'image.
Lors du développement de la détection de direction du son nous avons appris l'importance de bien observer les données du capteur avant de développer un algorithme de traitement. Nous avons utilisé ce principe directement pour l'analyse d'image ou nous avons commencé par envoyer les photos a l'ordinateur pour les observer.\\
Plus globalement, ce projet nous a beaucoup appris sur le développement d'un programme plus conséquent et nous a permis d'étudier plus en détail le fonctionnement d'un système d'exploitation et du multi-taches.


%et de l'apporter sur la pratique n'est pas toujours si 
%Le but du projet était de réaliser un robot qui peut naviguer un champ d'obstacles en direction d'une source sonore. Une fois a proximité de la source, le robot est capable de l'identifier visuellement. 

%Nous avons basé notre programme sur une machine d'états finis qui gère le comportement du robot et les diverses étapes qu'il va prendre pour arriver a son objectif. Cette machine d'états finis est complémentée par des modules qui gèrent l'acquisition et l'analyse de l'environnement du robot.\\
%Lors du développement de la détection de direction du son nous avons appris l'importance de bien observer les données du capteur avant de développer un algorithme de traitement. Nous avons utilisé ce principe directement pour l'analyse d'image ou nous avons commencé par envoyer les photos a l'ordinateur pour les observer.\\
%Plus globalement, ce projet nous a beaucoup appris sur le développement d'un programme plus conséquent et nous a permis d'étudier plus en détail le fonctionnement d'un système d'exploitation et du multi-taches.



\newpage
\nocite{*}
\bibliographystyle{ieeetr}
\bibliography{sample}


\end{document}
